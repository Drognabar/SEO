#!/usr/bin/env python3
"""
================================================================================
              –ê–ù–ê–õ–ò–ó –ö–ê–ù–ù–ò–ë–ê–õ–ò–ó–ê–¶–ò–ò SEO –¢–ï–ö–°–¢–û–í –ò–ó EXCEL
                  –ü–æ–∏—Å–∫ –¥—É–±–ª–µ–π –∏ –ø–æ—Ö–æ–∂–∏—Ö –æ–ø–∏—Å–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤
================================================================================

üéØ –ù–ê–ó–ù–ê–ß–ï–ù–ò–ï –°–ö–†–ò–ü–¢–ê:
   –ß–∏—Ç–∞–µ—Ç kotofoto_text_analysis.xlsx (–≤—ã—Ö–æ–¥ –∏–∑ kotofoto_text_analysis.py)
   ‚Üí –í—ã—á–∏—Å–ª—è–µ—Ç –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤ (TF-IDF + Jaccard)
   ‚Üí –í—ã—è–≤–ª—è–µ—Ç –¥—É–±–ª–∏ –∏ –∫–∞–Ω–Ω–∏–±–∞–ª–∏–∑–∞—Ü–∏—é —Å —Ü–≤–µ—Ç–Ω—ã–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
   ‚Üí –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ XLSX/CSV/TXT –¥–ª—è —Ä–µ–≤—å—é

üìã –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
   kotofoto_text_analysis.xlsx (–≤ –ø–∞–ø–∫–µ —Å–∫—Ä–∏–ø—Ç–∞):
   ‚îî‚îÄ –°—Ç–æ–ª–±—Ü—ã: URL | –¢–µ–∫—Å—Ç

üì§ –í–´–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï (–≤—Å–µ —Å –±–∞–∑–æ–≤—ã–º –∏–º–µ–Ω–µ–º kotofoto_text_analysis_v2_result):
   ‚îú‚îÄ kotofoto_text_analysis_v2_result.xlsx (–ø–∞—Ä—ã —Å —Ü–≤–µ—Ç–Ω—ã–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
   ‚îú‚îÄ kotofoto_text_analysis_v2_result.csv (–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞)
   ‚îî‚îÄ kotofoto_text_analysis_v2_result.txt (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)

================================================================================
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import sys
from pathlib import Path
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ==================== –ö–û–ù–§–ò–ì –ü–£–¢–ï–ô ====================
SCRIPT_DIR = Path(__file__).parent
INPUT_EXCEL = SCRIPT_DIR / "kotofoto_text_analysis.xlsx"
RESULT_BASE = SCRIPT_DIR / "kotofoto_text_analysis_v2_result"
OUTPUT_XLSX = RESULT_BASE.with_suffix(".xlsx")
OUTPUT_CSV = RESULT_BASE.with_suffix(".csv")
OUTPUT_STATS = RESULT_BASE.with_suffix(".txt")

# ==================== –ö–û–ù–§–ò–ì –ê–ù–ê–õ–ò–ó–ê ====================
MIN_SIMILARITY = 0.60
RISK_THRESHOLD_YELLOW = 0.75
RISK_THRESHOLD_RED = 0.80

# ==================== –§–£–ù–ö–¶–ò–ò ====================

def preprocess_text(text):
    """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è Jaccard"""
    if not isinstance(text, str):
        return []
    text = text.lower()
    text = "".join(c for c in text if c.isalnum() or c.isspace())
    return text.split()

def jaccard_similarity(text1, text2):
    """Jaccard: –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ / –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ"""
    words1 = set(preprocess_text(text1))
    words2 = set(preprocess_text(text2))
    if not words1 and not words2:
        return 0.0
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    return intersection / union if union > 0 else 0.0

def get_risk_color(similarity):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞ –∏ —Ü–≤–µ—Ç"""
    if similarity >= RISK_THRESHOLD_RED:
        return "üî¥ –ö–ê–ù–ù–ò–ë–ê–õ–ò–ó–ê–¶–ò–Ø", "red"
    elif similarity >= RISK_THRESHOLD_YELLOW:
        return "üü° –û–ß–ï–ù–¨ –ü–û–•–û–ñ–ò", "yellow"
    else:
        return "üü¢ –ù–û–†–ú–ê", "green"

def load_and_analyze_excel(filepath):
    """–ß–∏—Ç–∞–µ—Ç Excel, –≤—ã—á–∏—Å–ª—è–µ—Ç similarity"""
    print(f"üìÇ –ß–∏—Ç–∞–µ–º {filepath}...")
    df = pd.read_excel(filepath, sheet_name="–¢–æ–≤–∞—Ä—ã")
    
    if "—Ç–µ–∫—Å—Ç" not in df.columns or "url" not in df.columns:
        print("‚ùå –°—Ç–æ–ª–±—Ü—ã 'url' –∏ '—Ç–µ–∫—Å—Ç' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {df.columns.tolist()}")
        exit(1)
    
    texts = df["—Ç–µ–∫—Å—Ç"].fillna("").tolist()
    urls = df["url"].fillna("").tolist()
    
    print(f"   –¢–æ–≤–∞—Ä–æ–≤: {len(texts)}")
    
    if len(texts) < 2:
        print("‚ùå –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 —Ç–æ–≤–∞—Ä–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è!")
        exit(1)
    
    print(f"\nüîç –í—ã—á–∏—Å–ª—è—é TF-IDF similarity...")
    
    vectorizer = TfidfVectorizer(max_features=1000, stop_words=None, lowercase=True)
    try:
        tfidf_matrix = vectorizer.fit_transform(texts)
        tfidf_sim = cosine_similarity(tfidf_matrix)
    except Exception as e:
        print(f"‚ö†Ô∏è  TF-IDF –æ—à–∏–±–∫–∞: {e}")
        tfidf_sim = np.zeros((len(texts), len(texts)))
    
    pairs = []
    for i in range(len(texts)):
        for j in range(i + 1, len(texts)):
            tfidf_score = tfidf_sim[i, j]
            jaccard_score = jaccard_similarity(texts[i], texts[j])
            max_score = max(tfidf_score, jaccard_score)
            
            if max_score >= MIN_SIMILARITY:
                risk_text, risk_color = get_risk_color(max_score)
                pairs.append({
                    "url_1": urls[i],
                    "url_2": urls[j],
                    "tfidf_similarity": f"{tfidf_score:.1%}",
                    "jaccard_similarity": f"{jaccard_score:.1%}",
                    "max_similarity": max_score,
                    "—Ä–∏—Å–∫": risk_text,
                    "color": risk_color
                })
    
    return pd.DataFrame(pairs), tfidf_sim, texts, urls

def color_risk_cells(excel_file, color_col="—Ä–∏—Å–∫"):
    """–†–∞—Å–∫—Ä–∞—à–∏–≤–∞–µ—Ç —è—á–µ–π–∫–∏ –≤ Excel –ø–æ –ª–æ–≥–∏–∫–µ —Ü–≤–µ—Ç–∞"""
    wb = load_workbook(excel_file)
    ws = wb.active
    
    header_row = 1
    risk_col_idx = None
    for col_idx, cell in enumerate(ws[header_row], 1):
        if cell.value == color_col:
            risk_col_idx = col_idx
            break
    
    if risk_col_idx is None:
        print(f"‚ö†Ô∏è  –°—Ç–æ–ª–±–µ—Ü '{color_col}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ Excel")
        return
    
    color_map = {
        "üü¢ –ù–û–†–ú–ê": PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid"),
        "üü° –û–ß–ï–ù–¨ –ü–û–•–û–ñ–ò": PatternFill(start_color="FFEB9C", end_color="FFEB9C", fill_type="solid"),
        "üî¥ –ö–ê–ù–ù–ò–ë–ê–õ–ò–ó–ê–¶–ò–Ø": PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid"),
    }
    
    for row_idx, row in enumerate(ws.iter_rows(min_row=2), 2):
        risk_cell = row[risk_col_idx - 1]
        risk_text = risk_cell.value
        
        if risk_text in color_map:
            fill = color_map[risk_text]
            for cell in row:
                cell.fill = fill
    
    wb.save(excel_file)

# ==================== –û–°–ù–û–í–ù–û–ô –ö–û–î ====================
if __name__ == "__main__":
    
    if not INPUT_EXCEL.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {INPUT_EXCEL}")
        print("   –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python kotofoto_text_analysis.py")
        exit(1)
    
    print(f"‚úÖ –ù–∞—à—ë–ª —Ñ–∞–π–ª: {INPUT_EXCEL}\n")
    
    pairs_df, tfidf_matrix, texts, urls = load_and_analyze_excel(INPUT_EXCEL)
    
    print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä: {len(pairs_df)}")
    
    if len(pairs_df) == 0:
        print("‚úÖ –ö–∞–Ω–Ω–∏–±–∞–ª–∏–∑–∞—Ü–∏—è –ù–ï –≤—ã—è–≤–ª–µ–Ω–∞ (–æ—Ç–ª–∏—á–Ω–æ!)")
    else:
        green = len(pairs_df[pairs_df["—Ä–∏—Å–∫"] == "üü¢ –ù–û–†–ú–ê"])
        yellow = len(pairs_df[pairs_df["—Ä–∏—Å–∫"] == "üü° –û–ß–ï–ù–¨ –ü–û–•–û–ñ–ò"])
        red = len(pairs_df[pairs_df["—Ä–∏—Å–∫"] == "üî¥ –ö–ê–ù–ù–ò–ë–ê–õ–ò–ó–ê–¶–ò–Ø"])
        
        print(f"üü¢ –ù–û–†–ú–ê (60-75%): {green}")
        print(f"üü° –û–ß–ï–ù–¨ –ü–û–•–û–ñ–ò (75-80%): {yellow}")
        print(f"üî¥ –ö–ê–ù–ù–ò–ë–ê–õ–ò–ó–ê–¶–ò–Ø (>80%): {red}")
        
        if red > 0:
            print("\nüî¥ –¢–û–ü –ö–†–ò–¢–ò–ß–ï–°–ö–ò–• –î–£–ë–õ–ï–ô:")
            risky = pairs_df[pairs_df["—Ä–∏—Å–∫"] == "üî¥ –ö–ê–ù–ù–ò–ë–ê–õ–ò–ó–ê–¶–ò–Ø"].sort_values("max_similarity", ascending=False)
            for idx, row in risky.head(3).iterrows():
                print(f"\n   ‚Ä¢ {row['url_1'][:65]}...")
                print(f"     ‚Üî {row['url_2'][:65]}...")
                print(f"     TF-IDF: {row['tfidf_similarity']} | Jaccard: {row['jaccard_similarity']}")
        
        pairs_df_sorted = pairs_df.sort_values("max_similarity", ascending=False)
        
        pairs_df_sorted[["url_1", "url_2", "tfidf_similarity", "jaccard_similarity", "—Ä–∏—Å–∫"]].to_csv(
            OUTPUT_CSV, index=False, encoding="utf-8-sig")
        
        pairs_df_sorted[["url_1", "url_2", "tfidf_similarity", "jaccard_similarity", "—Ä–∏—Å–∫"]].to_excel(
            OUTPUT_XLSX, sheet_name="–ê–Ω–∞–ª–∏–∑", index=False, engine="openpyxl")
        
        color_risk_cells(OUTPUT_XLSX, color_col="—Ä–∏—Å–∫")
        
        print(f"\nüíæ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ –ø–∞–ø–∫—É —Å–∫—Ä–∏–ø—Ç–∞:")
        print(f"   ‚úì {OUTPUT_XLSX.name}")
        print(f"   ‚úì {OUTPUT_CSV.name}")
        
        with open(OUTPUT_STATS, "w", encoding="utf-8") as f:
            f.write("=" * 70 + "\n")
            f.write("               –û–¢–ß–Å–¢ –ê–ù–ê–õ–ò–ó–ê –ö–ê–ù–ù–ò–ë–ê–õ–ò–ó–ê–¶–ò–ò\n")
            f.write("=" * 70 + "\n\n")
            f.write(f"–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {INPUT_EXCEL.name}\n\n")
            f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n")
            f.write("-" * 70 + "\n")
            f.write(f"–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(texts)}\n")
            f.write(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö –ø–∞—Ä (>60%): {len(pairs_df)}\n\n")
            f.write(f"üü¢ –ù–û–†–ú–ê (60-75%): {green} –ø–∞—Ä\n")
            f.write(f"üü° –û–ß–ï–ù–¨ –ü–û–•–û–ñ–ò (75-80%): {yellow} –ø–∞—Ä\n")
            f.write(f"üî¥ –ö–ê–ù–ù–ò–ë–ê–õ–ò–ó–ê–¶–ò–Ø (>80%): {red} –ø–∞—Ä\n\n")
            f.write(f"–°—Ä–µ–¥–Ω—è—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å: {pairs_df['max_similarity'].mean():.1%}\n")
            f.write(f"–ú–∞–∫—Å –ø–æ—Ö–æ–∂–µ—Å—Ç—å: {pairs_df['max_similarity'].max():.1%}\n\n")
            f.write("–¢–û–ü-5 –î–£–ë–õ–ï–ô:\n")
            f.write("-" * 70 + "\n")
            for idx, row in pairs_df_sorted.head(5).iterrows():
                f.write(f"\n{idx + 1}. {row['url_1']}\n")
                f.write(f"   ‚Üî {row['url_2']}\n")
                f.write(f"   TF-IDF: {row['tfidf_similarity']} | Jaccard: {row['jaccard_similarity']}\n")
                f.write(f"   –°—Ç–∞—Ç—É—Å: {row['—Ä–∏—Å–∫']}\n")
        
        print(f"   ‚úì {OUTPUT_STATS.name}\n")

print("‚úÖ –ì–æ—Ç–æ–≤–æ!")
