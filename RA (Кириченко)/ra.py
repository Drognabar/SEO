import pandas as pd
import os
import re
import numpy as np
from datetime import datetime

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

def create_chpu(url):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –ø–æ–ª–Ω—ã–π URL –≤ –ß–ü–£-–∞–¥—Ä–µ—Å (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å)."""
    if isinstance(url, str):
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª (http/https) –∏ –¥–æ–º–µ–Ω
        chpu = re.sub(r'https?://[^/]+', '', url)
        return chpu if chpu else '/'
    return ''

def find_files(current_dir):
    """–ù–∞—Ö–æ–¥–∏—Ç —Ç—Ä–∏ —Ç–∏–ø–∞ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
    files = os.listdir(current_dir)
    file_map = {}
    
    csv_suffixes = [
        '–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞.csv', '—Ç–µ–≥–∏.csv', 'urls.csv', 
        '_keywords_.csv', '_tags_.csv', '_urls_.csv'
    ]
    
    for f in files:
        f_lower = f.lower()
        if f.endswith(('.xlsx', '.csv')) and not f.startswith('~$'):
            
            is_keyword = any(k in f_lower for k in ['keyword', '–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞'])
            is_tag = any(k in f_lower for k in ['tag', '—Ç–µ–≥–∏'])
            is_url = any(k in f_lower for k in ['url', '_urls'])

            if is_keyword and 'keywords' not in file_map:
                file_map['keywords'] = f
            elif is_tag and 'tags' not in file_map:
                file_map['tags'] = f
            elif is_url and 'urls' not in file_map:
                file_map['urls'] = f
                
    if len(file_map) < 3:
        print("‚õî –ù–µ –≤—Å–µ —Ç—Ä–∏ —Ç–∏–ø–∞ —Ñ–∞–π–ª–æ–≤ (_keywords_, _tags_, _urls_) –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ. –ê–Ω–∞–ª–∏–∑ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
        return None
        
    return file_map

def read_data_file(filepath):
    """–ß–∏—Ç–∞–µ—Ç CSV –∏–ª–∏ XLSX —Ñ–∞–π–ª —Å —É–º–Ω—ã–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è."""
    if filepath.endswith('.xlsx'):
        return pd.read_excel(filepath, header=0)
    elif filepath.endswith('.csv'):
        try:
            return pd.read_csv(filepath, header=0, sep=',', encoding='utf-8')
        except:
            try:
                return pd.read_csv(filepath, header=0, sep=';', encoding='cp1251')
            except:
                return pd.read_csv(filepath, header=0, sep=',', encoding='cp1251')
    return pd.DataFrame()

# –§—É–Ω–∫—Ü–∏—è create_recommendation_df() —É–¥–∞–ª–µ–Ω–∞

def normalize_columns(df, file_type):
    """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤."""
    
    current_cols_norm = {str(col): str(col).strip().lower().replace('.', '').replace(',', '') for col in df.columns}
    mapping = {}
    
    if file_type == 'keywords':
        mapping = {
            '–∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ': '–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ', '—Ç–µ–≥–∏': '–¢–µ–≥–∏', '—Ç—Ä–∞—Ñ–∏–∫': '–¢—Ä–∞—Ñ–∏–∫_–ö–ª—é—á',
            '—á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å': '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å', '–¥–∏–Ω–∞–º–∏–∫–∞': '–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á', 'url': 'URL'
        }
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –ø–æ–∑–∏—Ü–∏–π/–¥–∞—Ç
        position_cols_map = {}
        for original_col, norm_col_name in current_cols_norm.items():
            if '–ø–æ–∑–∏—Ü–∏—è' in norm_col_name or any(keyword in norm_col_name for keyword in ['–¥–∞—Ç–∞', '2025', '2024']) and not '—Å—Ä–µ–¥–Ω—è—è' in norm_col_name:
                position_cols_map[norm_col_name] = original_col 
        
        sorted_pos_cols_norm = sorted(position_cols_map.keys())
        if len(sorted_pos_cols_norm) >= 2:
            original_col_date1 = position_cols_map[sorted_pos_cols_norm[0]]
            original_col_date2 = position_cols_map[sorted_pos_cols_norm[1]]
            
            mapping[original_col_date1] = '–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_1'
            mapping[original_col_date2] = '–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'
            
    elif file_type == 'tags':
        mapping = {
            '—Ç–µ–≥': '–¢–µ–≥', '—Ç—Ä–∞—Ñ–∏–∫': '–¢—Ä–∞—Ñ–∏–∫_–¢–µ–≥', '—á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å': '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_–¢–µ–≥',
            '–≤–∏–¥–∏–º–æ—Å—Ç—å': '–í–∏–¥–∏–º–æ—Å—Ç—å_–¢–µ–≥', '–¥–∏–Ω–∞–º–∏–∫–∞': '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥', 
            '—Å—Ä–µ–¥–Ω—è—è –ø–æ–∑–∏—Ü–∏—è': '–°—Ä–µ–¥–Ω—è—è_–ü–æ–∑–∏—Ü–∏—è_–¢–µ–≥', '–¥–∏–Ω–∞–º–∏–∫–∞_–ø–æ–∑–∏—Ü–∏—è': '–î–∏–Ω–∞–º–∏–∫–∞_–ü–æ–∑–∏—Ü–∏–∏_–¢–µ–≥'
        }
    elif file_type == 'urls':
        mapping = {
            'url': 'URL', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–π': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–ö–ª—é—á–µ–π_URL', '—Ç–µ–≥–∏': '–¢–µ–≥–∏_URL',
            '—Ç—Ä–∞—Ñ–∏–∫': '–¢—Ä–∞—Ñ–∏–∫_URL', '—á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å': '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL', '–≤–∏–¥–∏–º–æ—Å—Ç—å': '–í–∏–¥–∏–º–æ—Å—Ç—å_URL',
            '–¥–∏–Ω–∞–º–∏–∫–∞': '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL', '—Å—Ä–µ–¥–Ω—è—è –ø–æ–∑–∏—Ü–∏—è': '–°—Ä–µ–¥–Ω—è—è_–ü–æ–∑–∏—Ü–∏—è_URL'
        }

    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
    new_cols = {}
    for col in df.columns:
        norm_col = str(col).strip().lower().replace('.', '').replace(',', '')
        
        if col in mapping:
            new_cols[col] = mapping[col]
        else:
            for old_col_norm, new_col_name in mapping.items():
                if norm_col == old_col_norm:
                    new_cols[col] = new_col_name
                    break
    
    df = df.rename(columns=new_cols)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã (–¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏)
    required_cols = list(set(mapping.values()))
    for col in required_cols:
        if col not in df.columns:
            df[col] = np.nan 
            
    return df


# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ ---

def complex_seo_analysis(file_map):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç, –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ —Ç—Ä–∏ —Ç–∞–±–ª–∏—Ü—ã."""
    
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
    
    df_keywords = read_data_file(file_map['keywords'])
    df_tags_agg = read_data_file(file_map['tags'])
    df_urls_agg = read_data_file(file_map['urls'])

    df_keywords = normalize_columns(df_keywords, 'keywords')
    df_tags_agg = normalize_columns(df_tags_agg, 'tags')
    df_urls_agg = normalize_columns(df_urls_agg, 'urls')

    if '–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_1' not in df_keywords.columns or '–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2' not in df_keywords.columns:
        raise ValueError(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –í —Ñ–∞–π–ª–µ keywords ({file_map['keywords']}) –Ω–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –¥–≤–∞ —Å—Ç–æ–ª–±—Ü–∞ —Å –ø–æ–∑–∏—Ü–∏—è–º–∏/–¥–∞—Ç–∞–º–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏.")
    
    # --- –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤ ---
    df_keywords['–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á'] = pd.to_numeric(df_keywords['–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á'].astype(str), errors='coerce').fillna(0)
    df_keywords['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å'] = pd.to_numeric(df_keywords['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å'].astype(str), errors='coerce').fillna(0)
    df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_1'] = pd.to_numeric(df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_1'].astype(str), errors='coerce').fillna(1000)
    df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'] = pd.to_numeric(df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'].astype(str), errors='coerce').fillna(1000)
    
    df_urls_agg['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–ö–ª—é—á–µ–π_URL'] = pd.to_numeric(df_urls_agg['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–ö–ª—é—á–µ–π_URL'].astype(str), errors='coerce').fillna(0)
    df_urls_agg['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL'] = pd.to_numeric(df_urls_agg['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL'].astype(str), errors='coerce').fillna(0)
    df_urls_agg['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL'] = pd.to_numeric(df_urls_agg['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL'].astype(str), errors='coerce').fillna(0)
    df_tags_agg['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥'] = pd.to_numeric(df_tags_agg['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥'].astype(str), errors='coerce').fillna(0)


    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω –¥–ª—è –∏–º–µ–Ω–∏ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    first_url = df_urls_agg['URL'].dropna().iloc[0] if not df_urls_agg.empty and df_urls_agg['URL'].dropna().iloc[0] else "http://example.com"
    match = re.search(r'https?://([^/]+)', first_url)
    domain = match.group(1).replace('.', '_') if match else 'unknown_site'
    
    results = {}
    
    # ----------------------------------------------------------------------
    # –û–ë–©–ê–Ø –ê–ì–†–ï–ì–ê–¶–ò–Ø
    # ----------------------------------------------------------------------
    keywords_sum = df_keywords.groupby('URL')['–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á'].sum().reset_index()
    keywords_sum.rename(columns={'–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á': '–°—É–º–º–∞—Ä–Ω–∞—è_–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á–µ–π'}, inplace=True)
    
    df_combined_url = df_urls_agg.merge(keywords_sum, on='URL', how='left')
    df_combined_url['–°—É–º–º–∞—Ä–Ω–∞—è_–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á–µ–π'] = df_combined_url['–°—É–º–º–∞—Ä–Ω–∞—è_–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á–µ–π'].fillna(0)
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–≥–∞–º–∏
    df_url_tag_expanded = df_urls_agg.copy()
    df_url_tag_expanded['–¢–µ–≥–∏_URL'] = df_url_tag_expanded['–¢–µ–≥–∏_URL'].astype(str).replace('nan', '')
    df_url_tag_expanded['–¢–µ–≥'] = df_url_tag_expanded['–¢–µ–≥–∏_URL'].str.split(r',\s*')
    df_url_tag_expanded = df_url_tag_expanded.explode('–¢–µ–≥')
    df_url_tag_expanded['–¢–µ–≥'] = df_url_tag_expanded['–¢–µ–≥'].str.strip()


    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 1: –ö–ª—é—á–µ–≤–æ–π –†–æ—Å—Ç 101 -> –¢–û–ü-20 (–ü—Ä–æ—Ä—ã–≤)
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '1. –ö–ª—é—á–µ–≤–æ–π –†–æ—Å—Ç 101 -> –¢–û–ü-20'...")

    df_rise = df_keywords[
        (df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_1'] > 20) & 
        (df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'] <= 20)
    ].copy()

    rise_counts = df_rise.groupby('URL').agg(
        –ü—Ä–∏—Ä–æ—Å—Ç_101_–¢–û–ü20=('–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ', 'count'),
        –°—É–º–º–∞_–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏_–ü—Ä–∏—Ä–æ—Å—Ç–∞=('–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å', 'sum')
    ).reset_index()

    df_final_rise = rise_counts.merge(
        df_combined_url[['URL', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL']],
        on='URL',
        how='left'
    )
    
    df_final_rise['–ß–ü–£-–∞–¥—Ä–µ—Å'] = df_final_rise['URL'].apply(create_chpu)

    results['1.–ö–ª—é—á_–†–æ—Å—Ç_101_–¢–û–ü20'] = df_final_rise.sort_values(
        by=['–ü—Ä–∏—Ä–æ—Å—Ç_101_–¢–û–ü20', '–°—É–º–º–∞_–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏_–ü—Ä–∏—Ä–æ—Å—Ç–∞'], 
        ascending=[False, False]
    )[['URL', '–ß–ü–£-–∞–¥—Ä–µ—Å', '–ü—Ä–∏—Ä–æ—Å—Ç_101_–¢–û–ü20', '–°—É–º–º–∞_–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏_–ü—Ä–∏—Ä–æ—Å—Ç–∞', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL']].head(20).copy()


    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 2: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –°–ø–∞–¥ URL (–£–≥—Ä–æ–∑—ã)
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '2. –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –°–ø–∞–¥ URL'...")
    
    freq_median = df_combined_url['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL'].median()
    
    df_critical_fall = df_combined_url[
        (df_combined_url['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL'].fillna(0) < 0) & 
        (df_combined_url['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL'] > freq_median)
    ].copy()

    df_critical_fall['–¶–µ–Ω–∞_–ü—Ä–æ—Å–∞–¥–∫–∏'] = df_critical_fall['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL'] * df_critical_fall['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL'].abs()
    
    results['2.–ö—Ä–∏—Ç–∏—á_–°–ø–∞–¥_URL'] = df_critical_fall.sort_values(
        by='–¶–µ–Ω–∞_–ü—Ä–æ—Å–∞–¥–∫–∏', ascending=False
    )[['URL', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL', '–¶–µ–Ω–∞_–ü—Ä–æ—Å–∞–¥–∫–∏', '–¢–µ–≥–∏_URL']].head(15).copy()

    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 3: –í—ã—è–≤–ª–µ–Ω–∏–µ "–¢–µ–≥–æ–≤-—Å–∏—Ä–æ—Ç" (–£–ø–∞–ª URL, –í—ã—Ä–æ—Å –¢–µ–≥)
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '3. –¢–µ–≥–∏-–°–∏—Ä–æ—Ç—ã'...")
    
    df_merged_full = df_url_tag_expanded.merge(
        df_tags_agg[['–¢–µ–≥', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥']], 
        on='–¢–µ–≥', 
        how='left'
    )
    
    df_orphans = df_merged_full[
        (df_merged_full['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥'].fillna(0) > 0) & 
        (df_merged_full['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL'].fillna(0) < 0)
    ].drop_duplicates(subset=['URL', '–¢–µ–≥']).copy()
    
    results['3.–¢–µ–≥–∏_–°–∏—Ä–æ—Ç—ã_–î–∏–∞–≥–Ω–æ—Å—Ç'] = df_orphans[[
        'URL', '–¢–µ–≥', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥', '–°—Ä–µ–¥–Ω—è—è_–ü–æ–∑–∏—Ü–∏—è_URL'
    ]].sort_values(by='–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥', ascending=False).copy()
    
    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 4: –°–∫—Ä—ã—Ç—ã–π –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª (Hidden Gems)
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '4. –°–∫—Ä—ã—Ç—ã–π –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª'...")
    
    freq_median_key = df_keywords['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å'].median()
    df_gems = df_keywords[
        (df_keywords['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å'] > freq_median_key) & 
        (df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'] <= 10) &
        (df_keywords['–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á'] <= 0) 
    ].copy()
    
    df_gems['–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç_Gems'] = df_gems['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å'] / (df_gems['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'] + 1)
    
    results['4.–°–∫—Ä—ã—Ç—ã–π_–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª_Gems'] = df_gems.sort_values(
        by='–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç_Gems', ascending=False
    )[['–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å', '–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2', '–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á', '–¢–µ–≥–∏', 'URL']].head(20).copy()

    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 5: –ü–æ–≥—Ä–∞–Ω–∏—á–Ω—ã–µ –¢–û–ü-10 (Just Missed)
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '5. –ü–æ–≥—Ä–∞–Ω–∏—á–Ω—ã–µ –¢–û–ü-10'...")
    
    df_just_missed = df_keywords[
        (df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'] >= 11) & 
        (df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'] <= 20)
    ].copy()
    
    df_just_missed['–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç_Just_Missed'] = df_just_missed['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å'] / (df_just_missed['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'] - 10)
    
    results['5.–ü–æ–≥—Ä–∞–Ω–∏—á–Ω—ã–µ_–¢–û–ü-10'] = df_just_missed.sort_values(
        by='–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç_Just_Missed', ascending=False
    )[['–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å', '–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2', '–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á', '–¢–µ–≥–∏', 'URL']].head(20).copy()

    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 6: –ê–Ω–∞–ª–∏–∑ –û—Ç—Å—É—Ç—Å—Ç–≤–∏—è –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è (Content Gap)
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '6. Content Gap'...")

    freq_median_tag = df_tags_agg['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_–¢–µ–≥'].median() if not df_tags_agg.empty else 0
    df_high_freq_tags = df_tags_agg[df_tags_agg['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_–¢–µ–≥'] >= freq_median_tag].copy()
    
    df_merged_gap = df_high_freq_tags.merge(
        df_url_tag_expanded[['–¢–µ–≥', 'URL']].drop_duplicates(), 
        on='–¢–µ–≥', 
        how='left'
    )
    
    df_gap_raw = df_merged_gap[df_merged_gap['URL'].isna()].drop_duplicates(subset=['–¢–µ–≥']).copy()
    
    df_gap_low_vis = df_high_freq_tags[df_high_freq_tags['–í–∏–¥–∏–º–æ—Å—Ç—å_–¢–µ–≥'].fillna(0) < 10].copy()
    
    df_gap = pd.concat([df_gap_raw.drop(columns='URL', errors='ignore'), df_gap_low_vis]).drop_duplicates(subset=['–¢–µ–≥']).copy()
    
    # –£–î–ê–õ–ï–ù–´ –ø—É—Å—Ç—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏–∑ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞
    results['6.–ê–Ω–∞–ª–∏–∑_Content_Gap'] = df_gap.sort_values(
        by=['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_–¢–µ–≥', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥'], 
        ascending=[False, True]
    )[['–¢–µ–≥', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_–¢–µ–≥', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥']].copy() 

    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 7: –û—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –º–Ω–æ–≥–æ—Ç–µ–≥–æ–≤—ã—Ö URL
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '7. –ú–Ω–æ–≥–æ—Ç–µ–≥–æ–≤—ã–µ URL'...")
    
    df_many_tags = df_combined_url[df_combined_url['–¢–µ–≥–∏_URL'].astype(str).apply(lambda x: len(x.split(',')) > 3)].copy()
    
    df_many_tags_fall = df_many_tags[df_many_tags['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL'].fillna(0) < 0]
    
    results['7.–ú–Ω–æ–≥–æ—Ç–µ–≥–æ–≤—ã–µ_URL_–°–ø–∞–¥'] = df_many_tags_fall.sort_values(
        by='–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL', ascending=True
    )[['URL', '–¢–µ–≥–∏_URL', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–ö–ª—é—á–µ–π_URL', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL']].copy()
    
    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 8: –û–±—â–∞—è –î–∏–Ω–∞–º–∏–∫–∞ URL (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ –†–æ—Å—Ç)
    # ----------------------------------------------------------------------
    df_combined_url['–†–µ–∑—É–ª—å—Ç–∞—Ç_–í–∏–¥–∏–º–æ—Å—Ç—å'] = df_combined_url['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL'].fillna(0).apply(
        lambda x: '–í—ã—Ä–æ—Å–ª–∞' if x > 0 else ('–£–ø–∞–ª–∞' if x < 0 else '–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π')
    )
    
    results['8.–û–±—â–∞—è_–î–∏–Ω–∞–º–∏–∫–∞_URL'] = df_combined_url.sort_values(
        by='–°—É–º–º–∞—Ä–Ω–∞—è_–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á–µ–π', ascending=False
    )[['URL', '–†–µ–∑—É–ª—å—Ç–∞—Ç_–í–∏–¥–∏–º–æ—Å—Ç—å', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL', 
      '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL', '–¢—Ä–∞—Ñ–∏–∫_URL', '–°—É–º–º–∞—Ä–Ω–∞—è_–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á–µ–π', '–¢–µ–≥–∏_URL']].copy()
      
    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 9: –¢–∞–±–ª–∏—Ü–∞ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (–£–î–ê–õ–ï–ù –ü–û–õ–ù–û–°–¢–¨–Æ)
    # ----------------------------------------------------------------------
    # –£–î–ê–õ–ï–ù: results['9.–£–≥—Ä–æ–∑—ã_–∏_–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏'] = create_recommendation_df().copy() 
    
    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 10: –§–æ—Ä–º–∞—Ç –¥–ª—è –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–£–ë–†–ê–ù –û–§–ò–¶–ò–ê–õ–¨–ù–´–ô_–°–ê–ô–¢)
    # ----------------------------------------------------------------------
    df_user_format = df_combined_url.copy()
    df_user_format['–°—Å—ã–ª–∫–∞_–ö–∞—Ç–∞–ª–æ–≥'] = df_user_format['URL'].apply(create_chpu)
    
    # –£–î–ê–õ–ï–ù —Å—Ç–æ–ª–±–µ—Ü –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π_–°–∞–π—Ç
    results['10.–§–æ—Ä–º–∞—Ç_–¥–ª—è_–ü–æ–ª—å–∑–æ–≤–∞—Ç'] = df_user_format.sort_values(
        by='–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL', ascending=False
    )[['–°—Å—ã–ª–∫–∞_–ö–∞—Ç–∞–ª–æ–≥', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL']].copy()

    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 11: –¢–æ—á–µ—á–Ω—ã–µ –ü–æ—Ç–µ—Ä–∏ (–ö–ª—é—á vs. –¢–µ–≥) 
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '11. –¢–æ—á–µ—á–Ω—ã–µ –ü–æ—Ç–µ—Ä–∏ (–ö–ª—é—á vs. –¢–µ–≥)'...")
    
    df_key_tag = df_keywords.copy()
    df_key_tag['–û—Å–Ω–æ–≤–Ω–æ–π_–¢–µ–≥'] = df_key_tag['–¢–µ–≥–∏'].astype(str).str.split(',').str[0].str.strip()
    
    df_merged_conflict = df_key_tag.merge(
        df_tags_agg[['–¢–µ–≥', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥']],
        left_on='–û—Å–Ω–æ–≤–Ω–æ–π_–¢–µ–≥',
        right_on='–¢–µ–≥',
        how='left'
    )
    
    df_conflict = df_merged_conflict[
        (df_merged_conflict['–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á'] < -30) & 
        (df_merged_conflict['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥'].fillna(0) >= 0)
    ].copy()
    
    df_conflict['–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç_–ö–æ–Ω—Ñ–ª–∏–∫—Ç–∞'] = df_conflict['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å'] * df_conflict['–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á'].abs()
    
    results['11.–¢–æ—á–µ—á–Ω—ã–µ_–ü–æ—Ç–µ—Ä–∏_–ö_–¢'] = df_conflict.sort_values(
        by='–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç_–ö–æ–Ω—Ñ–ª–∏–∫—Ç–∞', ascending=False
    )[['–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å', '–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á', '–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2', 
      'URL', '–û—Å–Ω–æ–≤–Ω–æ–π_–¢–µ–≥', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_–¢–µ–≥']].head(20).copy()

    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 12: –ë—ã—Å—Ç—Ä—ã–µ –ü–æ–±–µ–¥—ã (Low-Hanging Fruit) 
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '12. –ë—ã—Å—Ç—Ä—ã–µ –ü–æ–±–µ–¥—ã (Low-Hanging Fruit)'...")

    df_low_hanging = df_keywords[
        (df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'] > 10) & 
        (df_keywords['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'] <= 20) &
        (df_keywords['–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á'] <= 5) 
    ].copy()

    df_low_hanging['–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç_–ü–æ–±–µ–¥—ã'] = df_low_hanging['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å'] * (21 - df_low_hanging['–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2'])

    results['12.–ë—ã—Å—Ç—Ä—ã–µ_–ü–æ–±–µ–¥—ã_LHF'] = df_low_hanging.sort_values(
        by='–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç_–ü–æ–±–µ–¥—ã', ascending=False
    )[['–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å', '–ü–æ–∑–∏—Ü–∏—è_–î–∞—Ç–∞_2', '–î–∏–Ω–∞–º–∏–∫–∞_–ö–ª—é—á', 'URL']].head(20).copy()

    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 13: –ù–µ—Å–±—ã–≤—à–∏–µ—Å—è –ù–∞–¥–µ–∂–¥—ã (Gap –¢–û–ü-20) 
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '13. –ù–µ—Å–±—ã–≤—à–∏–µ—Å—è –ù–∞–¥–µ–∂–¥—ã (Gap –¢–û–ü-20)'...")

    high_freq_url_median = df_combined_url['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL'].median()
    
    df_gap_top20 = df_combined_url[
        (df_combined_url['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL'] > high_freq_url_median) & 
        (df_combined_url['–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–ö–ª—é—á–µ–π_URL'] == 0) & 
        (df_combined_url['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL'] <= 0)
    ].copy()
    
    results['13.Gap_–¢–û–ü20_–ù–∞–¥–µ–∂–¥—ã'] = df_gap_top20.sort_values(
        by='–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL', ascending=False
    )[['URL', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL', '–¢–µ–≥–∏_URL']].copy()

    # ----------------------------------------------------------------------
    # –ê–ù–ê–õ–ò–ó 14: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –£–≥—Ä–æ–∑—ã (–ü–∞–¥–µ–Ω–∏–µ –ù–ß-–°—Ç—Ä–∞–Ω–∏—Ü) 
    # ----------------------------------------------------------------------
    print("–ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ '14. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –£–≥—Ä–æ–∑—ã (–ü–∞–¥–µ–Ω–∏–µ –ù–ß-–°—Ç—Ä–∞–Ω–∏—Ü)'...")

    low_freq_url_median = df_combined_url['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL'].median()
    
    df_technical_threats = df_combined_url[
        (df_combined_url['–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL'] <= low_freq_url_median) & 
        (df_combined_url['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL'] < 
         df_combined_url['–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL'].quantile(0.25)) 
    ].copy()

    results['14.–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ_–£–≥—Ä–æ–∑—ã_–ù–ß'] = df_technical_threats.sort_values(
        by='–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL', ascending=True
    )[['URL', '–ß–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç—å_URL', '–î–∏–Ω–∞–º–∏–∫–∞_–í–∏–¥–∏–º–æ—Å—Ç–∏_URL', '–¢–µ–≥–∏_URL']].head(20).copy()


    # --- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    output_filename = f"{domain}-complex-ra-analis_v11_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
    print(f"üìù –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª: {output_filename}")
    
    try:
        with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:
            workbook = writer.book
            
            for sheet_name, df_result in results.items():
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º DataFrame –Ω–∞ –ª–∏—Å—Ç
                df_result.to_excel(writer, sheet_name=sheet_name, index=False)
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç –ª–∏—Å—Ç–∞ (Worksheet)
                worksheet = writer.sheets[sheet_name]
                
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤
                for i, col in enumerate(df_result.columns):
                    # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ —Å—Ç–æ–ª–±—Ü–µ (–≤–∫–ª—é—á–∞—è –∑–∞–≥–æ–ª–æ–≤–æ–∫)
                    max_len = max(
                        df_result[col].astype(str).map(len).max(),
                        len(str(col))
                    ) + 2 # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å
                    
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É —Å—Ç–æ–ª–±—Ü–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–ª–∏—à–∫–æ–º —à–∏—Ä–æ–∫–∏—Ö —è—á–µ–µ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö URL)
                    final_len = min(max_len, 70) 
                    
                    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —à–∏—Ä–∏–Ω—É —Å—Ç–æ–ª–±—Ü–∞
                    worksheet.set_column(i, i, final_len)

        print(f"üéâ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è {domain} —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∏ –¥–æ—Å—Ç—É–ø–Ω—ã –≤ —Ñ–∞–π–ª–µ: {output_filename}")
        return output_filename
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞ {output_filename}: {e}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –æ—Ç–∫—Ä—ã—Ç.")
        return None

# --- –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ ---
def run_complex_analysis():
    current_dir = os.getcwd()
    file_map = find_files(current_dir)

    if file_map is None:
        return

    print("--- ‚öôÔ∏è –ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ SEO-–∞–Ω–∞–ª–∏–∑–∞ (v11) ---")
    
    try:
        output_file = complex_seo_analysis(file_map)
        if output_file:
            print(f"–§–∞–π–ª {output_file} —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞: {e}")

if __name__ == "__main__":
    run_complex_analysis()